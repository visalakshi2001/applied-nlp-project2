{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7330d6fd-fe59-402e-8c37-615d8e59d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ca41acf-3f13-4b4b-b0ff-a22ad0a1d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_riddle = pd.read_json('../responses/zero_shot_responses_riddle_sense.jsonl', lines=True)\n",
    "responses_ooo = pd.read_json('../responses/zero_shot_responses_oddoneout.jsonl', lines=True)\n",
    "responses_cj = pd.read_json('../responses/zero_shot_responses_causal_judgement.jsonl', lines=True)\n",
    "\n",
    "responses_riddle = responses_riddle[~responses_riddle['question'].duplicated()].reset_index(drop=True)\n",
    "responses_ooo = responses_ooo[~responses_ooo['choices'].duplicated()].reset_index(drop=True)\n",
    "responses_cj = responses_cj[~responses_cj['question'].duplicated()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f84e3192-ad36-45c0-b680-3a3808cef38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_riddle['task'] = 'riddle'\n",
    "responses_ooo['task'] = 'ooo'\n",
    "responses_cj['task'] = 'cj'\n",
    "responses = pd.concat([responses_riddle, responses_ooo, responses_cj])\n",
    "responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f0d8af8-8544-491a-9ccb-a3c0cc34bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatedf = pd.DataFrame()\n",
    "evaluatedf['question'] = responses['question']\n",
    "evaluatedf['task'] = responses['task']\n",
    "\n",
    "evaluatedf['deberta'] = responses[['answer', 'deberta']].apply(lambda x: x['answer'] in x['deberta'], axis=1)\n",
    "evaluatedf['gpt3.5'] = responses[['answer', 'gpt3.5']].apply(lambda x: x['answer'] in x['gpt3.5'], axis=1)\n",
    "evaluatedf['gpt4o'] = responses[['answer', 'gpt4o']].apply(lambda x: x['answer'] in x['gpt4o'], axis=1)\n",
    "evaluatedf['commandr'] = responses[['answer', 'commandr']].apply(lambda x: x['answer'] in x['commandr'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e264839d-16b0-457d-a982-d7a3c4a175fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task</th>\n",
       "      <th>cj</th>\n",
       "      <th>ooo</th>\n",
       "      <th>riddle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deberta_true</th>\n",
       "      <td>99.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt3_5_true</th>\n",
       "      <td>110.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o_true</th>\n",
       "      <td>125.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandr_true</th>\n",
       "      <td>102.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_questions</th>\n",
       "      <td>188.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberta_accuracy</th>\n",
       "      <td>52.66</td>\n",
       "      <td>26.74</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt3_5_accuracy</th>\n",
       "      <td>58.51</td>\n",
       "      <td>69.77</td>\n",
       "      <td>69.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o_accuracy</th>\n",
       "      <td>66.49</td>\n",
       "      <td>84.88</td>\n",
       "      <td>81.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandr_accuracy</th>\n",
       "      <td>54.26</td>\n",
       "      <td>61.63</td>\n",
       "      <td>55.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task                   cj    ooo  riddle\n",
       "deberta_true        99.00  23.00   11.00\n",
       "gpt3_5_true        110.00  60.00   34.00\n",
       "gpt4o_true         125.00  73.00   40.00\n",
       "commandr_true      102.00  53.00   27.00\n",
       "total_questions    188.00  86.00   49.00\n",
       "deberta_accuracy    52.66  26.74   22.45\n",
       "gpt3_5_accuracy     58.51  69.77   69.39\n",
       "gpt4o_accuracy      66.49  84.88   81.63\n",
       "commandr_accuracy   54.26  61.63   55.10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = evaluatedf.groupby('task').agg(\n",
    "    deberta_true=('deberta', 'sum'),\n",
    "    gpt3_5_true=('gpt3.5', 'sum'),\n",
    "    gpt4o_true=('gpt4o', 'sum'),\n",
    "    commandr_true=('commandr', 'sum'),\n",
    "    total_questions=('question', 'count')\n",
    ")\n",
    "\n",
    "summary['deberta_accuracy'] = round((summary['deberta_true'] / summary['total_questions']) * 100, 2)\n",
    "summary['gpt3_5_accuracy'] = round((summary['gpt3_5_true'] / summary['total_questions']) * 100, 2)\n",
    "summary['gpt4o_accuracy'] = round((summary['gpt4o_true'] / summary['total_questions']) * 100, 2)\n",
    "summary['commandr_accuracy'] = round((summary['commandr_true'] / summary['total_questions']) * 100, 2)\n",
    "\n",
    "summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9dba1a7b-7925-4a8b-b275-0a7e2ecb4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84b5bb7-6e9f-4b22-bc67-9c46ed763eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(model, tokenizer, question, choices):\n",
    "    inputs = [f\"Question: {question} Choice: {choice}\" for choice in choices]\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        inputs,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # The model expects inputs in shape: (batch_size, num_choices, seq_length)\n",
    "    # Here we have one \"batch\" with multiple choices, so we add a batch dimension\n",
    "    for key in encoding:\n",
    "        encoding[key] = encoding[key].unsqueeze(0)  # Now shape: (1, num_choices, seq_length)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "\n",
    "    predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "    predicted_answer = choices[predicted_label]\n",
    "\n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78e3af14-d659-4f8f-a304-0b751807e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to true when loading model\n",
    "load_flag = False\n",
    "if load_flag:\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(\"../deberta_finetuned/\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"../deberta_finetuned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f5bd593-4848-49b0-a134-4af4c3905182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "redicting: 323it [07:32,  1.40s/it]"
     ]
    }
   ],
   "source": [
    "total_responses = len(responses)\n",
    "total_riddle = len(responses[responses['task'] == 'riddle'])\n",
    "total_cj = len(responses[responses['task'] == 'cj'])\n",
    "total_ooo = len(responses[responses['task'] == 'ooo'])\n",
    "\n",
    "correct_riddle = 0\n",
    "correct_cj = 0\n",
    "correct_ooo = 0\n",
    "\n",
    "for i,row in tqdm(responses.iterrows(), desc = \"Predicting\"):\n",
    "    task = row['task']\n",
    "    question = row['question']\n",
    "    choices = row['choices']\n",
    "    answer = row['answer']\n",
    "\n",
    "    deb_ans = predict_answer(model, tokenizer, question, choices)\n",
    "\n",
    "    if answer in deb_ans or answer == deb_ans:\n",
    "        if task == 'riddle':\n",
    "            correct_riddle += 1\n",
    "        if task == 'cj':\n",
    "            correct_cj += 1\n",
    "        if task == 'ooo':\n",
    "            correct_ooo += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70b7edf2-98df-45ee-b1d7-179f1e37146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Correct Riddle Answers 19\n",
      "% Total Riddle Answers 49\n",
      "% Accuracy 38.78%\n",
      "--------------------------------------------------\n",
      "% Correct Causal Judgement Answers 103\n",
      "% Total Causal Judgement Answers 188\n",
      "% Accuracy 54.79%\n",
      "--------------------------------------------------\n",
      "% Correct Odd One Out Answers 28\n",
      "% Total Odd One Out Answers 86\n",
      "% Accuracy 32.56%\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Total Correct Answers 150\n",
      "Total Questions 323\n",
      "% Accuracy 46.44%\n"
     ]
    }
   ],
   "source": [
    "print(f\"% Correct Riddle Answers {correct_riddle}\")\n",
    "print(f\"% Total Riddle Answers {total_riddle}\")\n",
    "print(f\"% Accuracy {(correct_riddle/total_riddle)*100:.2f}%\")\n",
    "print(\"-\"*50)\n",
    "print(f\"% Correct Causal Judgement Answers {correct_cj}\")\n",
    "print(f\"% Total Causal Judgement Answers {total_cj}\")\n",
    "print(f\"% Accuracy {(correct_cj/total_cj)*100:.2f}%\")\n",
    "print(\"-\"*50)\n",
    "print(f\"% Correct Odd One Out Answers {correct_ooo}\")\n",
    "print(f\"% Total Odd One Out Answers {total_ooo}\")\n",
    "print(f\"% Accuracy {(correct_ooo/total_ooo)*100:.2f}%\")\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(f\"Total Correct Answers {correct_riddle+correct_cj+correct_ooo}\")\n",
    "print(f\"Total Questions {total_responses}\")\n",
    "print(f\"% Accuracy {((correct_riddle+correct_cj+correct_ooo)/total_responses)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f104093b-1eee-4789-9ae0-1c359d06394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task</th>\n",
       "      <th>cj</th>\n",
       "      <th>ooo</th>\n",
       "      <th>riddle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deberta_true</th>\n",
       "      <td>99.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finetun_deb_true</th>\n",
       "      <td>103.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt3_5_true</th>\n",
       "      <td>110.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o_true</th>\n",
       "      <td>125.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandr_true</th>\n",
       "      <td>102.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberta_accuracy</th>\n",
       "      <td>52.66</td>\n",
       "      <td>26.74</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finetun_deb_accuracy</th>\n",
       "      <td>54.79</td>\n",
       "      <td>32.56</td>\n",
       "      <td>38.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt3_5_accuracy</th>\n",
       "      <td>58.51</td>\n",
       "      <td>69.77</td>\n",
       "      <td>69.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o_accuracy</th>\n",
       "      <td>66.49</td>\n",
       "      <td>84.88</td>\n",
       "      <td>81.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandr_accuracy</th>\n",
       "      <td>54.26</td>\n",
       "      <td>61.63</td>\n",
       "      <td>55.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_questions</th>\n",
       "      <td>188.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task                      cj    ooo  riddle\n",
       "deberta_true           99.00  23.00   11.00\n",
       "finetun_deb_true      103.00  28.00   19.00\n",
       "gpt3_5_true           110.00  60.00   34.00\n",
       "gpt4o_true            125.00  73.00   40.00\n",
       "commandr_true         102.00  53.00   27.00\n",
       "deberta_accuracy       52.66  26.74   22.45\n",
       "finetun_deb_accuracy   54.79  32.56   38.78\n",
       "gpt3_5_accuracy        58.51  69.77   69.39\n",
       "gpt4o_accuracy         66.49  84.88   81.63\n",
       "commandr_accuracy      54.26  61.63   55.10\n",
       "total_questions       188.00  86.00   49.00"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_ord = ['deberta_true', 'finetun_deb_true', 'gpt3_5_true', 'gpt4o_true', 'commandr_true',\n",
    "                   'deberta_accuracy',  'finetun_deb_accuracy', 'gpt3_5_accuracy', 'gpt4o_accuracy', 'commandr_accuracy', 'total_questions']\n",
    "summary['finetun_deb_true'] = [correct_cj, correct_ooo, correct_riddle]\n",
    "summary['finetun_deb_accuracy'] = [round((correct_cj/total_cj)*100, 2), round((correct_ooo/total_ooo)*100, 2), round((correct_riddle/total_riddle*100), 2)]\n",
    "summary = summary[col_ord]\n",
    "summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc86035b-eab3-4d65-83be-b715ff907f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deberta_true</th>\n",
       "      <th>finetun_deb_true</th>\n",
       "      <th>gpt3_5_true</th>\n",
       "      <th>gpt4o_true</th>\n",
       "      <th>commandr_true</th>\n",
       "      <th>deberta_accuracy</th>\n",
       "      <th>finetun_deb_accuracy</th>\n",
       "      <th>gpt3_5_accuracy</th>\n",
       "      <th>gpt4o_accuracy</th>\n",
       "      <th>commandr_accuracy</th>\n",
       "      <th>total_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cj</th>\n",
       "      <td>99</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>125</td>\n",
       "      <td>102</td>\n",
       "      <td>52.66</td>\n",
       "      <td>54.79</td>\n",
       "      <td>58.51</td>\n",
       "      <td>66.49</td>\n",
       "      <td>54.26</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ooo</th>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>73</td>\n",
       "      <td>53</td>\n",
       "      <td>26.74</td>\n",
       "      <td>32.56</td>\n",
       "      <td>69.77</td>\n",
       "      <td>84.88</td>\n",
       "      <td>61.63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>riddle</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>22.45</td>\n",
       "      <td>38.78</td>\n",
       "      <td>69.39</td>\n",
       "      <td>81.63</td>\n",
       "      <td>55.10</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        deberta_true  finetun_deb_true  gpt3_5_true  gpt4o_true  \\\n",
       "task                                                              \n",
       "cj                99               103          110         125   \n",
       "ooo               23                28           60          73   \n",
       "riddle            11                19           34          40   \n",
       "\n",
       "        commandr_true  deberta_accuracy  finetun_deb_accuracy  \\\n",
       "task                                                            \n",
       "cj                102             52.66                 54.79   \n",
       "ooo                53             26.74                 32.56   \n",
       "riddle             27             22.45                 38.78   \n",
       "\n",
       "        gpt3_5_accuracy  gpt4o_accuracy  commandr_accuracy  total_questions  \n",
       "task                                                                         \n",
       "cj                58.51           66.49              54.26              188  \n",
       "ooo               69.77           84.88              61.63               86  \n",
       "riddle            69.39           81.63              55.10               49  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpproj_py310",
   "language": "python",
   "name": "nlpproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

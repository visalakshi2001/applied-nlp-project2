{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igpgQ4YuhqJs",
    "outputId": "998ee2d3-8cc4-4b96-8b97-cf41ad0223d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/google/BIG-bench.git\n",
      "  Cloning https://github.com/google/BIG-bench.git to /tmp/pip-req-build-yl2k6qkw\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/google/BIG-bench.git /tmp/pip-req-build-yl2k6qkw\n",
      "  Resolved https://github.com/google/BIG-bench.git to commit 092b196c1f8f14a54bbc62f24759d43bde46dd3b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Processing //tmp/pip-req-build-yl2k6qkw/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip (from bigbench==0.0.1)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tensorflow-text>=2.6 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (2.18.0)\n",
      "Requirement already satisfied: tensorflow>=2.6 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (2.18.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: black>=21.6b0 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (24.10.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (2.21.0)\n",
      "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.8.1)\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (4.2.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.26.4)\n",
      "Requirement already satisfied: pytest>=6.2.4 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (8.3.4)\n",
      "Requirement already satisfied: requests-unixsocket>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.3.0)\n",
      "Requirement already satisfied: RestrictedPython>=5.1 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (7.4)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.13.1)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.13.2)\n",
      "Requirement already satisfied: t5>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.9.4)\n",
      "Requirement already satisfied: seqio>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.0.19)\n",
      "Requirement already satisfied: transformers>=4.12.5 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (4.46.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (24.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (4.3.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (1.2.2)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: requests>=1.1 in /usr/local/lib/python3.10/dist-packages (from requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (3.5.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn>=0.11.2->bigbench==0.0.1) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: clu in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.0.12)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.4.33)\n",
      "Requirement already satisfied: pyglove in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.4.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: tfds-nightly==4.9.2.dev202308090034 in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (4.9.2.dev202308090034)\n",
      "Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (3.20.3)\n",
      "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.5.1)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.11.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (2.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (5.9.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.13.1)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (2.5.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (4.66.6)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.17.0)\n",
      "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (2.16.0)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (0.5.0)\n",
      "Requirement already satisfied: mesh-tensorflow>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (0.1.21)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (3.9.1)\n",
      "Requirement already satisfied: rouge-score>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (2.4.3)\n",
      "Requirement already satisfied: seqio-nightly in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (0.0.18.dev20241207)\n",
      "Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (75.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.5.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.37.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.26.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.4.5)\n",
      "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from bleurt@ file://localhost//tmp/pip-req-build-yl2k6qkw/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->bigbench==0.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (3.11.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6->bigbench==0.0.1) (0.45.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.18.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (0.13.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow>=0.1.13->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (4.9.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.6->bigbench==0.0.1) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.6->bigbench==0.0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.6->bigbench==0.0.1) (3.1.3)\n",
      "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from clu->seqio>=0.0.6->bigbench==0.0.1) (0.8.5)\n",
      "Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (from clu->seqio>=0.0.6->bigbench==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: docstring-parser>=0.12 in /usr/local/lib/python3.10/dist-packages (from pyglove->seqio>=0.0.6->bigbench==0.0.1) (0.16)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (5.3.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (6.4.5)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.6->bigbench==0.0.1) (3.0.2)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.2.4)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.6.4)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.1.69)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (2.18.0)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (0.1.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.66.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.6->bigbench==0.0.1) (0.1.2)\n",
      "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.1.87)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (4.11.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.12.1)\n",
      "Building wheels for collected packages: bleurt\n",
      "  Building wheel for bleurt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454005 sha256=0e7f3eda63d24c2c81feac76b7b9d90a214fd865c2919f98b92237ecebb98b65\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/b1/86/350a38c08511c851a30521471649ed8f3fb9eeec42b8b8a2ab\n",
      "Successfully built bleurt\n",
      "Installing collected packages: bleurt\n",
      "  Attempting uninstall: bleurt\n",
      "    Found existing installation: BLEURT 0.0.2\n",
      "    Uninstalling BLEURT-0.0.2:\n",
      "      Successfully uninstalled BLEURT-0.0.2\n",
      "Successfully installed bleurt-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/google/BIG-bench.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRGId3UwnxJr",
    "outputId": "72195622-db31-48fe-e1c8-691ff384e3c9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets<3.0.0 in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
      "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (3.11.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (0.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets<3.0.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.2) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<3.0.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'datasets<3.0.0' 'httpx==0.27.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyvTArMi6b-2",
    "outputId": "0d3ea21b-c861-4c94-cdfd-443ebf333280",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.13.3)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.7)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3LFYbuYrnn3Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "import seqio\n",
    "import tensorflow_datasets as tfds\n",
    "from bigbench.bbseqio import task_api\n",
    "from bigbench.bbseqio import tasks\n",
    "import re\n",
    "import string\n",
    "import cohere\n",
    "import openai\n",
    "from google.colab import userdata\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhIf7TdXo800",
    "outputId": "dae37bb9-a461-437d-99ca-77b0b48f11a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqIO Mixture: bigbench:all_json.mix.t5_default_vocab.0_shot.all_examples\n",
      "\n",
      "Number of SeqIO Tasks in this Mixture: 1762\n",
      "\n",
      "Example Subtasks:\n",
      "bigbench:causal_judgment.mul.t5_default_vocab.0_shot.all_examples\n"
     ]
    }
   ],
   "source": [
    "bb_mix = seqio.get_mixture_or_task(\"bigbench:all_json.mix.t5_default_vocab.0_shot.all_examples\")\n",
    "\n",
    "print(\"SeqIO Mixture:\", bb_mix.name)\n",
    "\n",
    "print(\"\\nNumber of SeqIO Tasks in this Mixture:\", len(bb_mix.tasks))\n",
    "print(\"\\nExample Subtasks:\")\n",
    "all_subtasks = sorted([t.name for t in bb_mix.tasks])\n",
    "# print(\"\\n\".join(all_subtasks[:7]) + \"\\n...\")\n",
    "print(\"\\n\".join([subtask for subtask in all_subtasks if \"causal\" in subtask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: When I'm full, I'll be able to point the way. Nothing moves me when I'm empty. I have two skins: one that is outside and one that is within. What exactly am I?\n",
      "  choice: covering\n",
      "  choice: triangle\n",
      "  choice: glove\n",
      "  choice: band aid\n",
      "  choice: index finger\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(\"Q: When I'm full, I'll be able to point the way. Nothing moves me when I'm empty. I have two skins: one that is outside and one that is within. What exactly am I?\\n  choice: covering\\n  choice: triangle\\n  choice: glove\\n  choice: band aid\\n  choice: index finger\\nA:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpTg8foR4m9u",
    "outputId": "10d2dd2c-436c-48a3-d2a7-9d96b360eb43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs_pretokenized': b\"Q: You may be in a room full of flowers in one case, but you'll never step into it in another. What makes you say that?\\n  choice: funeral\\n  choice: windowsill\\n  choice: leg\\n  choice: disparagement\\n  choice: vase\\nA:\", 'inputs': array([1593,   10,  148,  164,   36,   16,    3,    9,  562,  423,   13,\n",
      "       3652,   16,   80,  495,    6,   68,   25,   31,  195,  470, 1147,\n",
      "        139,   34,   16,  430,    5,  363,  656,   25,  497,   24],\n",
      "      dtype=int32), 'idx': array([8, 1], dtype=int32), 'targets_pretokenized': b'leg', 'targets': array([4553], dtype=int32), 'scores': 0, 'answers': array([b'funeral'], dtype=object)}\n",
      "{'inputs_pretokenized': b\"Q: When I'm full, I'll be able to point the way. Nothing moves me when I'm empty. I have two skins: one that is outside and one that is within. What exactly am I?\\n  choice: covering\\n  choice: triangle\\n  choice: glove\\n  choice: band aid\\n  choice: index finger\\nA:\", 'inputs': array([1593,   10,  366,   27,   31,   51,  423,    6,   27,   31,  195,\n",
      "         36,    3,  179,   12,  500,    8,  194,    5, 9428, 6914,  140,\n",
      "        116,   27,   31,   51, 6364,    5,   27,   43,  192, 1133],\n",
      "      dtype=int32), 'idx': array([16,  0], dtype=int32), 'targets_pretokenized': b'band aid', 'targets': array([1928, 3052], dtype=int32), 'scores': 0, 'answers': array([b'glove'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: I cannot be felt, heard, or touched; however, I can be found in everyone; my existence is constantly contested; however, I have my own musical style. What exactly am I?\\n  choice: bluegrass\\n  choice: soul\\n  choice: hip\\n  choice: antiphony\\n  choice: night club\\nA:', 'inputs': array([ 1593,    10,    27,  1178,    36,  1800,     6,  1943,     6,\n",
      "          42, 15880,   117,   983,     6,    27,    54,    36,   435,\n",
      "          16,   921,   117,    82,  6831,    19,  4259,     3, 29365,\n",
      "         117,   983,     6,    27,    43], dtype=int32), 'idx': array([39,  4], dtype=int32), 'targets_pretokenized': b'soul', 'targets': array([3668], dtype=int32), 'scores': 1, 'answers': array([b'soul'], dtype=object)}\n",
      "{'inputs_pretokenized': b\"Q: When I'm full, I'll be able to point the way. Nothing moves me when I'm empty. I have two skins: one that is outside and one that is within. What exactly am I?\\n  choice: covering\\n  choice: triangle\\n  choice: glove\\n  choice: band aid\\n  choice: index finger\\nA:\", 'inputs': array([1593,   10,  366,   27,   31,   51,  423,    6,   27,   31,  195,\n",
      "         36,    3,  179,   12,  500,    8,  194,    5, 9428, 6914,  140,\n",
      "        116,   27,   31,   51, 6364,    5,   27,   43,  192, 1133],\n",
      "      dtype=int32), 'idx': array([16,  2], dtype=int32), 'targets_pretokenized': b'glove', 'targets': array([27230], dtype=int32), 'scores': 1, 'answers': array([b'glove'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: For those who live in the dark, this is a valuable tool. Within you, a deadly spell is wreaking havoc.\\n  choice: misfortune\\n  choice: witch\\n  choice: poison\\n  choice: highway\\n  choice: walking\\nA:', 'inputs': array([ 1593,    10,   242,   273,   113,   619,    16,     8,  2164,\n",
      "           6,    48,    19,     3,     9,  3435,  1464,     5,  8381,\n",
      "          25,     6,     3,     9, 18443, 10783,    19,     3,   210,\n",
      "         864,  1765,  4244,  6117,     5], dtype=int32), 'idx': array([36,  3], dtype=int32), 'targets_pretokenized': b'witch', 'targets': array([22583], dtype=int32), 'scores': 0, 'answers': array([b'poison'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "task = seqio.get_mixture_or_task(\"bigbench:riddle_sense.mul.t5_default_vocab.0_shot.all_examples\")\n",
    "\n",
    "sequence_length = {\"inputs\": 32, \"targets\": 32}\n",
    "ds = task.get_dataset(\n",
    "    sequence_length=sequence_length,  #  Trim long token sequences.\n",
    "    split=\"all\",  # Available splits = \"all\", \"train\", \"validation\".\n",
    ")\n",
    "for d in tfds.as_numpy(ds.take(5)):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcC6EGn3Miyr",
    "outputId": "3a187654-efcc-420f-ffd4-467af0f84351"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs_pretokenized': b\"How would a typical person answer each of the following questions about causation?\\n\\n\\nQ: Billy and Suzy inherited an unusual type of hybrid car that has two special car batteries called Bartlett batteries. The car won't start unless it has at least one Bartlett battery. Having a second Bartlett battery isn't necessary to start the car. When they got the car, both Bartlett batteries were missing. One day, Billy and Suzy are both out of the house. Billy is visiting his friend's house, and notices that his friend has a Bartlett battery. Billy asks his friend to sell the battery to him, and his friend says that he's willing to sell it for a fair price, so Billy buys the Bartlett battery from his friend. Meanwhile, on the other side of town, Suzy walks into an automotive parts shop and happens to notice that they have a single Bartlett battery in stock. Suzy decides to buy the Bartlett battery from the shop. When Billy and Suzy get home, they installed the two Bartlett batteries. Since all the car needed was at least one Bartlett battery, they were able to start the car. Did Billy cause the car to be able to start?\\nA:\", 'inputs': array([  571,   133,     3,     9,  4541,   568,  1525,   284,    13,\n",
      "           8,   826,   746,    81,   212,   302,   257,    58,  1593,\n",
      "          10, 17724,    11,  1923,  4164,     3, 23665,    46,  7225,\n",
      "         686,    13,  9279,   443,    24], dtype=int32), 'idx': array([146,   1], dtype=int32), 'targets_pretokenized': b'No', 'targets': array([465], dtype=int32), 'scores': 0, 'answers': array([b'Yes'], dtype=object)}\n",
      "{'inputs_pretokenized': b'How would a typical person answer each of the following questions about causation?\\n\\n\\nQ: A machine is set up in such a way that it will short circuit if both the black wire and the red wire touch the battery at the same time. The machine will not short circuit if just one of these wires touches the battery. The black wire is designated as the one that is supposed to touch the battery, while the red wire is supposed to remain in some other part of the machine. One day, the black wire and the red wire both end up touching the battery at the same time. There is a short circuit. Did the black wire cause the short circuit?\\nA:', 'inputs': array([ 571,  133,    3,    9, 4541,  568, 1525,  284,   13,    8,  826,\n",
      "        746,   81,  212,  302,  257,   58, 1593,   10,   71, 1437,   19,\n",
      "        356,   95,   16,  224,    3,    9,  194,   24,   34,   56],\n",
      "      dtype=int32), 'idx': array([131,   1], dtype=int32), 'targets_pretokenized': b'No', 'targets': array([465], dtype=int32), 'scores': 1, 'answers': array([b'No'], dtype=object)}\n",
      "{'inputs_pretokenized': b\"How would a typical person answer each of the following questions about causation?\\n\\n\\nQ: Lauren and Jane work for the same company. They each need to use a computer for work sometimes. Unfortunately, the computer isn't very powerful. If two people are logged on at the same time, it usually crashes. So the company decided to institute an official policy. It declared that Lauren would be the only one permitted to use the computer in the mornings and that Jane would be the only one permitted to use the computer in the afternoons. As expected, Lauren logged on the computer the next day at 9:00 am. But Jane decided to disobey the official policy. She also logged on at 9:00 am. The computer crashed immediately. Did Jane cause the computer to crash?\\nA:\", 'inputs': array([ 571,  133,    3,    9, 4541,  568, 1525,  284,   13,    8,  826,\n",
      "        746,   81,  212,  302,  257,   58, 1593,   10, 9906,   11, 8158,\n",
      "        161,   21,    8,  337,  349,    5,  328,  284,  174,   12],\n",
      "      dtype=int32), 'idx': array([0, 1], dtype=int32), 'targets_pretokenized': b'No', 'targets': array([465], dtype=int32), 'scores': 0, 'answers': array([b'Yes'], dtype=object)}\n",
      "{'inputs_pretokenized': b\"How would a typical person answer each of the following questions about causation?\\n\\n\\nQ: George and his sister Lena reunite at their parents' house for Thanksgiving. Whereas George just got into medical school, Lena is unhappy in her marriage and recently lost her job. Over the course of the day, George and Lena get into a number of heated arguments. Later in the afternoon they play a game of darts. They split the first two games, and the third game is close until the end. Who will win comes down to George's last shot. If he hits a high point region, he wins; if he hits a low point region, Lena wins. George thinks of the difficult time Lena is having, and he really wants to let her win. George has little control over his shots. He tries to aim at the low point region of the dart board. As he sets up his shot, however, he loses his balance. The dart slips out of his hand and wobbles toward the board. The dart lands in the low point region. After his shot, Lena wins the game and is very happy. Did George hit the low point region intentionally?\\nA:\", 'inputs': array([  571,   133,     3,     9,  4541,   568,  1525,   284,    13,\n",
      "           8,   826,   746,    81,   212,   302,   257,    58,  1593,\n",
      "          10,  3080,    11,   112,  4806,   312,    29,     9,     3,\n",
      "       28207,    44,    70,  1362,    31], dtype=int32), 'idx': array([136,   0], dtype=int32), 'targets_pretokenized': b'Yes', 'targets': array([2163], dtype=int32), 'scores': 0, 'answers': array([b'No'], dtype=object)}\n",
      "{'inputs_pretokenized': b'How would a typical person answer each of the following questions about causation?\\n\\n\\nQ: Jim, Carol, Bob, and Nancy are researchers in a remote area, and they have a limited supply of electricity. Because of their limited supply, the electricity only comes on in the evenings from 8-9 PM, and they have to restrict who can use power on certain days. If two people turn on their lamps at the same time, the breaker will fail. The breaker will not fail if fewer people turn on their lamps at the same time. Jim, Carol, Bob, and Nancy are all allowed to use their lamps on Thursdays. This Thursday Jim turns on his lamp at 8 PM. Just then, Carol also turns on her lamp. Since two people turned on their lamps at the same time, the circuit breaker failed. Did Jim turning on his lamp at 8 PM cause the circuit breaker to fail?\\nA:', 'inputs': array([  571,   133,     3,     9,  4541,   568,  1525,   284,    13,\n",
      "           8,   826,   746,    81,   212,   302,   257,    58,  1593,\n",
      "          10,  6006,     6, 12526,     6,  5762,     6,    11, 17117,\n",
      "          33,  4768,    16,     3,     9], dtype=int32), 'idx': array([115,   1], dtype=int32), 'targets_pretokenized': b'No', 'targets': array([465], dtype=int32), 'scores': 1, 'answers': array([b'No'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "task = seqio.get_mixture_or_task(\"bigbench:causal_judgment.mul.t5_default_vocab.0_shot.all_examples\")\n",
    "\n",
    "sequence_length = {\"inputs\": 32, \"targets\": 32}\n",
    "ds_cj = task.get_dataset(\n",
    "    sequence_length=sequence_length,  #  Trim long token sequences.\n",
    "    split=\"all\",  # Available splits = \"all\", \"train\", \"validation\".\n",
    ")\n",
    "for d in tfds.as_numpy(ds_cj.take(5)):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NvcoVf3M1aC",
    "outputId": "942c99fb-9702-4aa7-ad55-58d292f1e09c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs_pretokenized': b'Q: Pick the odd word out: jump, clap, pencil, read, run\\nA:', 'inputs': array([ 1593,    10,  8356,     8,  8617,  1448,    91,    10,  4418,\n",
      "           6,     3,  4651,   102,     6, 13966,     6,   608,     6,\n",
      "         661,    71,    10], dtype=int32), 'idx': array([7, 2], dtype=int32), 'targets_pretokenized': b'pencil', 'targets': array([13966], dtype=int32), 'scores': 1, 'answers': array([b'pencil'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: Pick the odd word out: bedroom, kitchen, carpet, dining room, bathroom\\nA:', 'inputs': array([1593,   10, 8356,    8, 8617, 1448,   91,   10, 2923,    6, 1228,\n",
      "          6, 4898,    6, 2851,  562,    6, 2582,   71,   10], dtype=int32), 'idx': array([40,  3], dtype=int32), 'targets_pretokenized': b'dining room', 'targets': array([2851,  562], dtype=int32), 'scores': 0, 'answers': array([b'carpet'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: Pick the odd word out: apple, pear, strawberry, phone, banana\\nA:', 'inputs': array([ 1593,    10,  8356,     8,  8617,  1448,    91,    10,  8947,\n",
      "           6,   158,   291,     6, 25256,     6,   951,     6, 13634,\n",
      "          71,    10], dtype=int32), 'idx': array([45,  0], dtype=int32), 'targets_pretokenized': b'apple', 'targets': array([8947], dtype=int32), 'scores': 0, 'answers': array([b'phone'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: Pick the odd word out: Monday, spring, summer, winter, fall\\nA:', 'inputs': array([1593,   10, 8356,    8, 8617, 1448,   91,   10, 2089,    6, 2141,\n",
      "          6, 1248,    6, 2265,    6, 1590,   71,   10], dtype=int32), 'idx': array([14,  1], dtype=int32), 'targets_pretokenized': b'spring', 'targets': array([2141], dtype=int32), 'scores': 0, 'answers': array([b'Monday'], dtype=object)}\n",
      "{'inputs_pretokenized': b'Q: Pick the odd word out: jump, clap, pencil, read, run\\nA:', 'inputs': array([ 1593,    10,  8356,     8,  8617,  1448,    91,    10,  4418,\n",
      "           6,     3,  4651,   102,     6, 13966,     6,   608,     6,\n",
      "         661,    71,    10], dtype=int32), 'idx': array([7, 3], dtype=int32), 'targets_pretokenized': b'read', 'targets': array([608], dtype=int32), 'scores': 0, 'answers': array([b'pencil'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "task = seqio.get_mixture_or_task(\"bigbench:odd_one_out.mul.t5_default_vocab.0_shot.all_examples\")\n",
    "\n",
    "sequence_length = {\"inputs\": 32, \"targets\": 32}\n",
    "ds_ooo = task.get_dataset(\n",
    "    sequence_length=sequence_length,  #  Trim long token sequences.\n",
    "    split=\"all\",  # Available splits = \"all\", \"train\", \"validation\".\n",
    ")\n",
    "for d in tfds.as_numpy(ds_ooo.take(5)):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nDrHjTQJpMF2"
   },
   "outputs": [],
   "source": [
    "def transform_question_string(question, choices):\n",
    "    choices = [string.ascii_uppercase[i] + \": \" + choice for i,choice in enumerate(choices)]\n",
    "    inputs = question + \"\\n\" + \"\\n\".join(choices) + \" \\n\" + \"Answer: \"\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339,
     "referenced_widgets": [
      "4200a639aea649d2b67b278306b0d0d9",
      "debb67d193c54269b6a4e9fd501fe1ea",
      "4922e5630191482790636e4e036bff57",
      "a94a332c9c044290b8cd66c3c0b8fd0c",
      "b170c63b7b5c4c1c971735c847dec989",
      "ea748c7df34b402289edf77dbd8a453f",
      "efa826ec8deb47b3a852c6eeb12347e6",
      "fa0883fea9fc423c85793937bae39c7f",
      "11e91ff8e1c74518966fe7b1e1cda320",
      "68fd40b77a8d46b2bde679e08a013d1d",
      "5114667312724335855bb875b3dedbbd",
      "ac45a9a978de451f91333d6fcea3342d",
      "7a28b00935f2452a9313eaaf2975571c",
      "f01abcb75356458bbfd0d6d708b29f65",
      "0f91675f2b1e494e8c934f2c0be7415d",
      "58320de56186445ba42e347e4c064a59",
      "26e8024ce215478c90eb803939449a1d",
      "9be103ff19774e74bb4c7afea1e1fb0d",
      "00925778a2cb43a583f1c64ffe785936",
      "8f8367f45f0a4b46bfba2862806d3e0a",
      "9db96d5a3eea458687c439401a03a9bc",
      "6562c66120d24f8d9048ed3d62875764",
      "ec009dd173524f99ba4ebadcfb8cbb46",
      "080889cb1d0242ce96e3f487c872a6f7",
      "4ad046aba4d04319b12fe85ac6184776",
      "6e1cc29f23ae4295a6c3b5c4a26199a5",
      "cba6bbf651ca45529b3271000bb3866b",
      "2b5c4516e8e74536b75008f419b43fa3",
      "33cf768b108a404ebf18413617b55a36",
      "2ce6cc8fd74443e99bd692fffd812fc6",
      "ece6f71a71f249d1abe1643eb81e9552",
      "39dff2532b004091a94d6dcd1cb9e2bb",
      "eff326d34f484152976ac870521165c3",
      "4c6b905ae8e54938b8233305fb0e3374",
      "fde46519d2174bcf8c88b1636b0bbd82",
      "af75d28f35a64657a40ffd377131b091",
      "f5bb5e7e99cd4ba7b60b63c49ab66f2a",
      "a6b5e73b7a434f4da8d05c283d7ef570",
      "e10310c0f28d4941b91083fdab6f1c37",
      "a0e44386710c49b985b8d068a5c0a665",
      "35fc0f47a11845dda6b2f10a6f5b8098",
      "6cbb8b580adf4356b8a1431525d8b29b",
      "b570ccac9c1c48248a47a95c89aeb066",
      "ad50f1f70dd14a05ad5a5ca18cf0a285"
     ]
    },
    "id": "sAdObCqKh2mP",
    "outputId": "105aecc8-3316-45f7-abfb-ed4306bfff45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4200a639aea649d2b67b278306b0d0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac45a9a978de451f91333d6fcea3342d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec009dd173524f99ba4ebadcfb8cbb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6b905ae8e54938b8233305fb0e3374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load model and tokenizer\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "def get_deberta_response(question, choices):\n",
    "\n",
    "    inputs = transform_question_string(question, choices)\n",
    "    encodings = deberta_tokenizer(inputs, padding=True, return_tensors=\"pt\")\n",
    "    outputs = deberta_model(**encodings)\n",
    "    scores = outputs.logits.softmax(dim=-1).detach().numpy()\n",
    "    best_choice_idx = scores.argmax(axis=0)[1]\n",
    "    return choices[best_choice_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yMcCzLoT08yc"
   },
   "outputs": [],
   "source": [
    "co = cohere.ClientV2(api_key=userdata.get('COHERE_API_KEY'))\n",
    "\n",
    "def get_cohere_response(question, choices, **kwargs):\n",
    "\n",
    "    prompt = transform_question_string(question, choices)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a helpful assistant. You have to solve the given common sense questions in the prompt.\n",
    "                    After the questions there will be choices/options that you have to choose from.\n",
    "                    Think logically before answering each question.\n",
    "                    Output your response in this template\n",
    "                    choice_letter_of_correct_answer: answer_corresponding_to_the_letter\n",
    "                    For example:\n",
    "                        C: land\n",
    "\n",
    "                    Follow the template of response strictly. Choose your answer from the list choices given after the question.\n",
    "                    Each choice will be preceeded by an uppercase letter\n",
    "                    \"\"\"\n",
    "    model=\"command-r-08-2024\"\n",
    "\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "\n",
    "    kwargs['model'] = model\n",
    "    kwargs['messages'] = messages\n",
    "\n",
    "\n",
    "    response = co.chat(**kwargs)\n",
    "\n",
    "    return response.message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LnwG3f5rH_iN",
    "outputId": "cd32d4c1-c3d8-45c0-9782-62769cf41ea3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Before you can have me, I need to be taken. What am I?\\nA: beg\\nB: picture\\nC: move\\nD: become adult\\nE: paper \\nAnswer: '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Before you can have me, I need to be taken. What am I?\"\n",
    "c = ['beg', 'picture', 'move', 'become adult', 'paper']\n",
    "\n",
    "transform_question_string(q,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eYNDKd5ucvji"
   },
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "\n",
    "def get_gpt_response(question, choices, model_num='4-o-mini', **kwargs):\n",
    "\n",
    "    prompt = transform_question_string(question, choices)\n",
    "    system_prompt = \"\"\"\n",
    "                    You are a helpful assistant. You have to solve the given common sense questions in the prompt.\n",
    "                    After the questions there will be choices/options that you have to choose from.\n",
    "                    Think logically before answering each question.\n",
    "                    Output your response in this template\n",
    "                    choice_letter_of_correct_answer: answer_corresponding_to_the_letter\n",
    "                    For example:\n",
    "                        C: land\n",
    "\n",
    "                    Follow the template of response strictly.\n",
    "                    \"\"\"\n",
    "\n",
    "    if model_num == \"3.5\":\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    elif model_num == \"4-o-mini\":\n",
    "        model=\"gpt-4o-mini\"\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    kwargs[\"temperature\"] = 0.0\n",
    "    kwargs[\"top_p\"] = 1\n",
    "    kwargs[\"frequency_penalty\"] = 0.0\n",
    "    kwargs[\"presence_penalty\"] = 0.0\n",
    "    kwargs[\"timeout\"] = 4*10*60  # 40 minutes\n",
    "    kwargs[\"model\"] = model\n",
    "    kwargs[\"messages\"] = messages\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(**kwargs)\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ22ilX9b4Vt",
    "outputId": "94364630-8bd3-46fd-9c26-ac930b234cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: John is standing near the tracks of a trolley. John notices that the brakes of the trolley have failed. Five workmen are working on the tracks with their backs turned. John sees that the runaway trolley is headed for the five workmen who will be killed if it proceeds on its present course. The only way to save these five workmen is to hit a switch that will turn the trolley onto the side tracks. Moreover, there is a dog on the tracks with its back turned. John knows that the five workmen and the dog will be saved if he hits the switch. John thinks 'I don't care at all about saving the dog. I just want to save the five workmen.' John decides to hit the switch. Sure enough, the trolley turns on the side tracks, the five workmen and the dog on the main tracks are saved. Did John intentionally save the dog?\n",
      "Choices: ['Yes', 'No']\n",
      "Correct Answer: No\n",
      "--------------------------------------------------\n",
      "Question: Prof. Smith works at a large university. At this university, in order to get new computers from the university, faculty like Prof. Smith must send an application to two administrative committees, the IT committee and the department budget committee. Prof. Smith will be able to get her new computers if the IT committee approves her application or the department budget committee approves her application. Only one of the committees needs to approve her application for her to get the new computers. The IT committee almost always approves these applications. The department budget committee almost never approves these applications. The budget committee is notorious for turning down almost every application they receive. Prof. Smith sends in her applications. Each committee meets independently and they decide without talking to each other, but their meetings are scheduled for the exact same time. The IT committee approves her application, and surprisingly, the department budget committee approves her application. So, Prof. Smith got her new computers. Does the department budget committee cause the approval of Prof. Smith's application?\n",
      "Choices: ['Yes', 'No']\n",
      "Correct Answer: No\n",
      "--------------------------------------------------\n",
      "Question: Laurie likes GC brand coffee. GC is doing a new promotion for their new coffee flavor where customers can receive a free sample. Customers will receive a free sample if both they have previously purchased coffee beans from GC and they are subscribed to the GC email list. Laurie has previously purchased coffee beans from GC, and she is not subscribed to the GC email list. When she hears about the promotion, Laurie checks to see if she is subscribed to the email list, and she sees that she is not. So, she changes her subscription status, and she subscribes to the email list. Because customers will receive a free sample if both they have previously purchased coffee beans from GC and they are subscribed to the GC email list, Laurie receives a free sample. Did Laurie receive a free sample because she changed her subscription status?\n",
      "Choices: ['Yes', 'No']\n",
      "Correct Answer: Yes\n",
      "--------------------------------------------------\n",
      "Question: A bear and a hedgehog were shown a box full of colored pencils. Only bears were allowed to take pencils, whereas hedgehogs were not allowed to take them. The hedgehog was present when the new rule about pencil use was announced. Therefore, the hedgehog knew about the new norm. Both animals alternately took pencils out of the box six times. At last, the hedgehog and the bear came to the box and simultaneously took a pencil. A short time later, another animal, a polar bear, approached the box seeking a pencil to do his homework with. However, there were no pencils left in the box. The polar bear could not finish his homework. Did the hedgehog cause the problem?\n",
      "Choices: ['Yes', 'No']\n",
      "Correct Answer: Yes\n",
      "--------------------------------------------------\n",
      "Question: Imagine that there is a man out in the woods who is participating in a hunting competition. After spending hours waiting for a deer to cross his path, the hunter suddenly sees the largest deer he has ever seen. If he can only kill this deer, he will surely win the competition. So, the hunter gets the deer in his sights -- but at the last second, he notices that there is a group of bird-watchers just on the other side of the deer. The hunter realizes that if he shoots the deer, the bullet will definitely hit one of the birdwatchers as well. But he does not care at all about the bird watchers -- he just wants to win the competition. So, he shoots and kills the deer. And as expected, the bullet ends up hitting one of the bird-watchers as well. Did the man intentionally shoot the bird-watcher?\n",
      "Choices: ['Yes', 'No']\n",
      "Correct Answer: Yes\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for example in tfds.as_numpy(ds_cj.take(5)):\n",
    "    full_question = example['inputs_pretokenized'].decode(\"utf-8\")\n",
    "    # question = re.findall(\"Q:\\s(.*)\\s+choice:(\\s.*){3,}\", full_question)[0][0]\n",
    "    # question = \"Pick the odd word out:\"\n",
    "    question = re.findall(\"Q:\\s(.*)\\s.*\", full_question)[0]\n",
    "    # choices = re.findall(\"choice:\\s(.*)\", full_question)\n",
    "    # choices = re.findall(f\"{question}\\s(.*)\", full_question)[0].split(',')\n",
    "    choices = [\"Yes\", \"No\"]\n",
    "    correct_answer = example['answers'][0].decode()\n",
    "    # print(question)\n",
    "    # print(full_question)\n",
    "\n",
    "    # deberta_response = get_deberta_response(question, choices)\n",
    "    # gpt3_5_response = get_gpt_response(question, choices, model_num='3.5')\n",
    "    # gpt4_o_response = get_gpt_response(question, choices, model_num='4-o-mini')\n",
    "    # command_r_response = get_cohere_response(question, choices)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Choices: {choices}\")\n",
    "    print(f\"Correct Answer: {correct_answer}\")\n",
    "    # print(f\"DeBERTa Response: {deberta_response}\")\n",
    "    # print(f\"GPT-3.5 Response: {gpt3_5_response}\")\n",
    "    # print(f\"GPT-4o Response: {gpt4_o_response}\")\n",
    "    # print(f\"Command-R Response: {command_r_response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-8meWEwVK2l",
    "outputId": "be07111d-4e47-40e8-d257-47f39f960301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated [0/380] responses  |  Time elapses: 4.07\n",
      "Generated [20/380] responses  |  Time elapses: 56.33\n",
      "Generated [40/380] responses  |  Time elapses: 103.21\n",
      "Generated [60/380] responses  |  Time elapses: 154.24\n",
      "Generated [80/380] responses  |  Time elapses: 198.32\n",
      "Generated [100/380] responses  |  Time elapses: 245.08\n",
      "Generated [120/380] responses  |  Time elapses: 286.73\n",
      "Generated [140/380] responses  |  Time elapses: 339.73\n",
      "Generated [160/380] responses  |  Time elapses: 393.34\n",
      "Generated [180/380] responses  |  Time elapses: 436.86\n",
      "Generated [200/380] responses  |  Time elapses: 486.53\n",
      "Generated [220/380] responses  |  Time elapses: 529.74\n",
      "Generated [240/380] responses  |  Time elapses: 572.21\n",
      "Generated [260/380] responses  |  Time elapses: 615.86\n",
      "Generated [280/380] responses  |  Time elapses: 661.17\n",
      "Generated [300/380] responses  |  Time elapses: 706.78\n",
      "Generated [320/380] responses  |  Time elapses: 747.03\n",
      "Generated [340/380] responses  |  Time elapses: 798.92\n",
      "Generated [360/380] responses  |  Time elapses: 844.65\n",
      "Responses saved to zero_shot_responses_causal_judgement.jsonl\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_responses(ds, savefile, save=False):\n",
    "\n",
    "    responses = []\n",
    "    start = time.time()\n",
    "    minute = time.time()\n",
    "\n",
    "    for i, example in enumerate(tfds.as_numpy(ds)):\n",
    "        full_question = example['inputs_pretokenized'].decode(\"utf-8\")\n",
    "        # question = re.findall(\"Q:\\s(.*)\\s+choice:(\\s.*){3,}\", full_question)[0][0]\n",
    "        # question = \"Pick the odd word out:\"\n",
    "        question = re.findall(\"Q:\\s(.*)\\s.*\", full_question)[0]\n",
    "        # choices = re.findall(\"choice:\\s(.*)\", full_question)\n",
    "        # choices = re.findall(f\"{question}\\s(.*)\", full_question)[0].split(',')\n",
    "        choices = [\"Yes\", \"No\"]\n",
    "        correct_answer = example['answers'][0].decode('utf-8')\n",
    "\n",
    "        deberta_response = get_deberta_response(question, choices)\n",
    "        gpt3_5_response = get_gpt_response(question, choices, model_num='3.5')\n",
    "        gpt4_o_response = get_gpt_response(question, choices, model_num='4-o-mini')\n",
    "\n",
    "        try:\n",
    "            command_r_response = get_cohere_response(question, choices)\n",
    "        except:\n",
    "            print(\"Too many responses in a minute\")\n",
    "            time.sleep(60)\n",
    "            try:\n",
    "                command_r_response = get_cohere_response(question, choices)\n",
    "            except:\n",
    "                print(f\"skipped index {i}\")\n",
    "\n",
    "        end = time.time()\n",
    "        time_elapsed = end-start\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"answer\": correct_answer,\n",
    "            \"deberta\": deberta_response,\n",
    "            \"gpt3.5\": gpt3_5_response,\n",
    "            \"gpt4o\": gpt4_o_response,\n",
    "            \"commandr\": command_r_response\n",
    "        }\n",
    "\n",
    "        responses.append(response)\n",
    "\n",
    "\n",
    "        if i%20 == 0:\n",
    "            print(f\"Generated [{i}/{len(ds)}] responses  |  Time elapses: {time_elapsed:.2f}\")\n",
    "\n",
    "        if save:\n",
    "            with open(savefile, \"a\", encoding='utf-8') as f:\n",
    "                f.write(json.dumps(response) + '\\n')\n",
    "\n",
    "    print(f\"Responses saved to {savefile}\")\n",
    "\n",
    "\n",
    "    return responses\n",
    "\n",
    "responses = zero_shot_responses(ds_cj, \"zero_shot_responses_causal_judgement.jsonl\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqcVgsXJ0pWK"
   },
   "source": [
    "### Test on finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fjLDo8bg0s9V"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NcvI-4U10808"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./deberta_finetuned/\")\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"./deberta_finetuned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vCoi5JYX1FJA"
   },
   "outputs": [],
   "source": [
    "def predict_answer(model, tokenizer, question, choices):\n",
    "    # Prepare inputs similar to how they were prepared during training\n",
    "    # Each choice forms a separate input sequence\n",
    "    inputs = [f\"Question: {question} Choice: {choice}\" for choice in choices]\n",
    "\n",
    "    # Tokenize all choice sequences\n",
    "    encoding = tokenizer(\n",
    "        inputs,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # The model expects inputs in shape: (batch_size, num_choices, seq_length)\n",
    "    # Here we have one \"batch\" with multiple choices, so we add a batch dimension\n",
    "    for key in encoding:\n",
    "        encoding[key] = encoding[key].unsqueeze(0)  # Now shape: (1, num_choices, seq_length)\n",
    "\n",
    "    # Move model and inputs to appropriate device (GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "    # Predict without gradient updates\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    # The model outputs logits of shape (batch_size=1, num_choices)\n",
    "    # Choose the answer with the highest logit score\n",
    "    predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "    predicted_answer = choices[predicted_label]\n",
    "\n",
    "    return predicted_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f5h3ujsh1vcQ",
    "outputId": "80ad25ee-dabe-4ea8-b044-a3f0b9627cc2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"responses\",\n  \"rows\": 840,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Pick the odd word out:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"Albania\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"deberta\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"helicopter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt3.5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"B: banana\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt4o\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"A: table\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commandr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 117,\n        \"samples\": [\n          \"B: notebook\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "responses"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f84f6258-c251-4a47-9faa-bd17fb4ea23e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>deberta</th>\n",
       "      <th>gpt3.5</th>\n",
       "      <th>gpt4o</th>\n",
       "      <th>commandr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "      <td>[square,  circle,  triangle,  trousers,  recta...</td>\n",
       "      <td>trousers</td>\n",
       "      <td>square</td>\n",
       "      <td>D: trousers</td>\n",
       "      <td>D: trousers</td>\n",
       "      <td>D:  trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "      <td>[Spain,  France,  German,  England,  Singapore]</td>\n",
       "      <td>German</td>\n",
       "      <td>Spain</td>\n",
       "      <td>E: Singapore</td>\n",
       "      <td>C: German</td>\n",
       "      <td>E: Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "      <td>[dentist,  doctor,  postman,  hospital,  cashier]</td>\n",
       "      <td>hospital</td>\n",
       "      <td>dentist</td>\n",
       "      <td>A: dentist</td>\n",
       "      <td>C: postman</td>\n",
       "      <td>C: postman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "      <td>[milk,  pink,  coffee,  tea,  beer]</td>\n",
       "      <td>pink</td>\n",
       "      <td>milk</td>\n",
       "      <td>A: milk</td>\n",
       "      <td>B: pink</td>\n",
       "      <td>D: tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "      <td>[Albania,  Asia,  Africa,  America]</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>B: Asia</td>\n",
       "      <td>A: Albania</td>\n",
       "      <td>B: Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f84f6258-c251-4a47-9faa-bd17fb4ea23e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f84f6258-c251-4a47-9faa-bd17fb4ea23e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f84f6258-c251-4a47-9faa-bd17fb4ea23e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-dfbd4591-9535-4406-abb3-d92a1a398e6f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfbd4591-9535-4406-abb3-d92a1a398e6f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-dfbd4591-9535-4406-abb3-d92a1a398e6f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                 question                                            choices  \\\n",
       "0  Pick the odd word out:  [square,  circle,  triangle,  trousers,  recta...   \n",
       "1  Pick the odd word out:    [Spain,  France,  German,  England,  Singapore]   \n",
       "2  Pick the odd word out:  [dentist,  doctor,  postman,  hospital,  cashier]   \n",
       "3  Pick the odd word out:                [milk,  pink,  coffee,  tea,  beer]   \n",
       "4  Pick the odd word out:                [Albania,  Asia,  Africa,  America]   \n",
       "\n",
       "     answer  deberta        gpt3.5        gpt4o      commandr  \n",
       "0  trousers   square   D: trousers  D: trousers  D:  trousers  \n",
       "1    German    Spain  E: Singapore    C: German  E: Singapore  \n",
       "2  hospital  dentist    A: dentist   C: postman    C: postman  \n",
       "3      pink     milk       A: milk      B: pink        D: tea  \n",
       "4   Albania  Albania       B: Asia   A: Albania       B: Asia  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "responses = pd.read_json('zero_shot_responses_oddoneout.jsonl', lines=True)\n",
    "\n",
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "-6qGoAVf16BP"
   },
   "outputs": [],
   "source": [
    "s = responses.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "z2oyBU5h2XJo",
    "outputId": "367426e8-28e3-4c56-8668-8e95dc67e85f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>Pick the odd word out:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choices</th>\n",
       "      <td>[break,  play,  do,  write]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberta</th>\n",
       "      <td>break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt3.5</th>\n",
       "      <td>A: break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o</th>\n",
       "      <td>A: break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandr</th>\n",
       "      <td>D: write</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "question         Pick the odd word out:\n",
       "choices     [break,  play,  do,  write]\n",
       "answer                               do\n",
       "deberta                           break\n",
       "gpt3.5                         A: break\n",
       "gpt4o                          A: break\n",
       "commandr                       D: write\n",
       "Name: 164, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "i_T6itPq1N-y",
    "outputId": "e7d22724-2b29-4623-ef77-c2856ae72de2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' do'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Pick the odd word out:\"\n",
    "c = ['break', ' play', ' do', ' write']\n",
    "predict_answer(model, tokenizer, q, c)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00925778a2cb43a583f1c64ffe785936": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "080889cb1d0242ce96e3f487c872a6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b5c4516e8e74536b75008f419b43fa3",
      "placeholder": "",
      "style": "IPY_MODEL_33cf768b108a404ebf18413617b55a36",
      "value": "tokenizer_config.json:100%"
     }
    },
    "0f91675f2b1e494e8c934f2c0be7415d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9db96d5a3eea458687c439401a03a9bc",
      "placeholder": "",
      "style": "IPY_MODEL_6562c66120d24f8d9048ed3d62875764",
      "value": "371M/371M[00:03&lt;00:00,110MB/s]"
     }
    },
    "11e91ff8e1c74518966fe7b1e1cda320": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26e8024ce215478c90eb803939449a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b5c4516e8e74536b75008f419b43fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ce6cc8fd74443e99bd692fffd812fc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33cf768b108a404ebf18413617b55a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35fc0f47a11845dda6b2f10a6f5b8098": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39dff2532b004091a94d6dcd1cb9e2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4200a639aea649d2b67b278306b0d0d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_debb67d193c54269b6a4e9fd501fe1ea",
       "IPY_MODEL_4922e5630191482790636e4e036bff57",
       "IPY_MODEL_a94a332c9c044290b8cd66c3c0b8fd0c"
      ],
      "layout": "IPY_MODEL_b170c63b7b5c4c1c971735c847dec989"
     }
    },
    "4922e5630191482790636e4e036bff57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa0883fea9fc423c85793937bae39c7f",
      "max": 579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11e91ff8e1c74518966fe7b1e1cda320",
      "value": 579
     }
    },
    "4ad046aba4d04319b12fe85ac6184776": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ce6cc8fd74443e99bd692fffd812fc6",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ece6f71a71f249d1abe1643eb81e9552",
      "value": 52
     }
    },
    "4c6b905ae8e54938b8233305fb0e3374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fde46519d2174bcf8c88b1636b0bbd82",
       "IPY_MODEL_af75d28f35a64657a40ffd377131b091",
       "IPY_MODEL_f5bb5e7e99cd4ba7b60b63c49ab66f2a"
      ],
      "layout": "IPY_MODEL_a6b5e73b7a434f4da8d05c283d7ef570"
     }
    },
    "5114667312724335855bb875b3dedbbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58320de56186445ba42e347e4c064a59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6562c66120d24f8d9048ed3d62875764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68fd40b77a8d46b2bde679e08a013d1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cbb8b580adf4356b8a1431525d8b29b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e1cc29f23ae4295a6c3b5c4a26199a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39dff2532b004091a94d6dcd1cb9e2bb",
      "placeholder": "",
      "style": "IPY_MODEL_eff326d34f484152976ac870521165c3",
      "value": "52.0/52.0[00:00&lt;00:00,1.36kB/s]"
     }
    },
    "7a28b00935f2452a9313eaaf2975571c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26e8024ce215478c90eb803939449a1d",
      "placeholder": "",
      "style": "IPY_MODEL_9be103ff19774e74bb4c7afea1e1fb0d",
      "value": "pytorch_model.bin:100%"
     }
    },
    "8f8367f45f0a4b46bfba2862806d3e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9be103ff19774e74bb4c7afea1e1fb0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9db96d5a3eea458687c439401a03a9bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0e44386710c49b985b8d068a5c0a665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6b5e73b7a434f4da8d05c283d7ef570": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a94a332c9c044290b8cd66c3c0b8fd0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68fd40b77a8d46b2bde679e08a013d1d",
      "placeholder": "",
      "style": "IPY_MODEL_5114667312724335855bb875b3dedbbd",
      "value": "579/579[00:00&lt;00:00,25.3kB/s]"
     }
    },
    "ac45a9a978de451f91333d6fcea3342d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a28b00935f2452a9313eaaf2975571c",
       "IPY_MODEL_f01abcb75356458bbfd0d6d708b29f65",
       "IPY_MODEL_0f91675f2b1e494e8c934f2c0be7415d"
      ],
      "layout": "IPY_MODEL_58320de56186445ba42e347e4c064a59"
     }
    },
    "ad50f1f70dd14a05ad5a5ca18cf0a285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af75d28f35a64657a40ffd377131b091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35fc0f47a11845dda6b2f10a6f5b8098",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cbb8b580adf4356b8a1431525d8b29b",
      "value": 2464616
     }
    },
    "b170c63b7b5c4c1c971735c847dec989": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b570ccac9c1c48248a47a95c89aeb066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cba6bbf651ca45529b3271000bb3866b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "debb67d193c54269b6a4e9fd501fe1ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea748c7df34b402289edf77dbd8a453f",
      "placeholder": "",
      "style": "IPY_MODEL_efa826ec8deb47b3a852c6eeb12347e6",
      "value": "config.json:100%"
     }
    },
    "e10310c0f28d4941b91083fdab6f1c37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea748c7df34b402289edf77dbd8a453f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec009dd173524f99ba4ebadcfb8cbb46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_080889cb1d0242ce96e3f487c872a6f7",
       "IPY_MODEL_4ad046aba4d04319b12fe85ac6184776",
       "IPY_MODEL_6e1cc29f23ae4295a6c3b5c4a26199a5"
      ],
      "layout": "IPY_MODEL_cba6bbf651ca45529b3271000bb3866b"
     }
    },
    "ece6f71a71f249d1abe1643eb81e9552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efa826ec8deb47b3a852c6eeb12347e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eff326d34f484152976ac870521165c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f01abcb75356458bbfd0d6d708b29f65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00925778a2cb43a583f1c64ffe785936",
      "max": 371146213,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f8367f45f0a4b46bfba2862806d3e0a",
      "value": 371146213
     }
    },
    "f5bb5e7e99cd4ba7b60b63c49ab66f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b570ccac9c1c48248a47a95c89aeb066",
      "placeholder": "",
      "style": "IPY_MODEL_ad50f1f70dd14a05ad5a5ca18cf0a285",
      "value": "2.46M/2.46M[00:00&lt;00:00,39.7MB/s]"
     }
    },
    "fa0883fea9fc423c85793937bae39c7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fde46519d2174bcf8c88b1636b0bbd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e10310c0f28d4941b91083fdab6f1c37",
      "placeholder": "",
      "style": "IPY_MODEL_a0e44386710c49b985b8d068a5c0a665",
      "value": "spm.model:100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
